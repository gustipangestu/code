{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scipy.fft import fft, ifft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  pose_landmarks_list = detection_result.pose_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected poses to visualize.\n",
    "  for idx in range(len(pose_landmarks_list)):\n",
    "    pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "    # Draw the pose landmarks.\n",
    "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    pose_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      pose_landmarks_proto,\n",
    "      solutions.pose.POSE_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getFiturLandmark(img):\n",
    "    err = None\n",
    "    detection_result = []\n",
    "    try:\n",
    "        \n",
    "        base_options = python.BaseOptions(model_asset_path='pose_landmarker_heavy.task')\n",
    "        options = vision.PoseLandmarkerOptions(\n",
    "        base_options=base_options,\n",
    "        output_segmentation_masks=True)\n",
    "        detector = vision.PoseLandmarker.create_from_options(options)\n",
    "        \n",
    "        detection_result = detector.detect(img)\n",
    "\n",
    "        err = None\n",
    "    \n",
    "    except:\n",
    "        err = 1\n",
    "        detection_result = []\n",
    "    \n",
    "    return detection_result, err\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ainput = mp.Image.create_from_file(\"../../dataset/extractFrame/above/00431/121.jpg\")\n",
    "# aaa, aer = getFiturLandmark(ainput)\n",
    "# aaalandmarklist = aaa.pose_landmarks\n",
    "# # _dfpose = pd.DataFrame(aaalandmarklist[0])\n",
    "# print(len(aaalandmarklist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate \n",
    "def flatten(data):\n",
    "    a = np.ravel(data)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above\n",
      "00430\n",
      "00431\n",
      "00433\n",
      "00435\n",
      "65004\n",
      "accomplish\n",
      "00663\n",
      "00664\n",
      "00666\n",
      "00668\n",
      "65010\n",
      "adopt\n",
      "01157\n",
      "01158\n",
      "01159\n",
      "01160\n",
      "01162\n",
      "65022\n",
      "advantage\n",
      "01244\n",
      "01245\n",
      "01252\n",
      "65025\n",
      "alphabet\n",
      "02145\n",
      "02149\n",
      "02151\n",
      "65058\n",
      "anniversary\n",
      "02609\n",
      "02610\n",
      "02611\n",
      "02614\n",
      "02616\n",
      "another\n",
      "02697\n",
      "02698\n",
      "02699\n",
      "02701\n",
      "02706\n",
      "appropriate\n",
      "03101\n",
      "03102\n",
      "03103\n",
      "03105\n",
      "03108\n",
      "arrogant\n",
      "03448\n",
      "03449\n",
      "03450\n",
      "03451\n",
      "03454\n",
      "03457\n",
      "artist\n",
      "03515\n",
      "03516\n",
      "03517\n",
      "03519\n",
      "03522\n",
      "background\n",
      "04580\n",
      "04581\n",
      "04582\n",
      "04590\n",
      "65122\n",
      "bee\n",
      "05680\n",
      "05681\n",
      "05682\n",
      "05685\n",
      "05688\n",
      "65165\n",
      "behavior\n",
      "05792\n",
      "05793\n",
      "05794\n",
      "05796\n",
      "05798\n",
      "bell\n",
      "05873\n",
      "05874\n",
      "05875\n",
      "05877\n",
      "05878\n",
      "05881\n",
      "birth\n",
      "06372\n",
      "06373\n",
      "06375\n",
      "06379\n",
      "65189\n",
      "65190\n",
      "bless\n",
      "06625\n",
      "06626\n",
      "06628\n",
      "06629\n",
      "06631\n",
      "65206\n",
      "blood\n",
      "06733\n",
      "06734\n",
      "06736\n",
      "06738\n",
      "65212\n",
      "boots\n",
      "07163\n",
      "07173\n",
      "65226\n",
      "brave\n",
      "07575\n",
      "07576\n",
      "07578\n",
      "07580\n",
      "65251\n",
      "breathe\n",
      "07676\n",
      "07677\n",
      "07678\n",
      "07680\n",
      "07682\n",
      "65256\n",
      "bright\n",
      "07779\n",
      "07780\n",
      "07781\n",
      "07782\n",
      "07787\n",
      "07791\n",
      "bull\n",
      "08166\n",
      "08167\n",
      "08168\n",
      "08170\n",
      "08174\n",
      "butterfly\n",
      "08442\n",
      "08443\n",
      "08445\n",
      "08447\n",
      "65280\n",
      "card\n",
      "09126\n",
      "09127\n",
      "09128\n",
      "09130\n",
      "09131\n",
      "09137\n",
      "09138\n",
      "65304\n",
      "category\n",
      "09488\n",
      "09489\n",
      "09490\n",
      "09493\n",
      "09495\n",
      "catholic\n",
      "09518\n",
      "09519\n",
      "09521\n",
      "09523\n",
      "65316\n",
      "cent\n",
      "09735\n",
      "09736\n",
      "09737\n",
      "09740\n",
      "09742\n",
      "65323\n",
      "chemistry\n",
      "10308\n",
      "10309\n",
      "10310\n",
      "10311\n",
      "10313\n",
      "10315\n",
      "cherry\n",
      "10337\n",
      "10339\n",
      "10340\n",
      "10343\n",
      "65347\n",
      "china\n",
      "10516\n",
      "10517\n",
      "10520\n",
      "10526\n",
      "chop\n",
      "10645\n",
      "10646\n",
      "10647\n",
      "10648\n",
      "10652\n",
      "10656\n",
      "65355\n",
      "christian\n",
      "10686\n",
      "10687\n",
      "10688\n",
      "10689\n",
      "10692\n",
      "10693\n",
      "65356\n",
      "cigarette\n",
      "10786\n",
      "10787\n",
      "10789\n",
      "10792\n",
      "65359\n",
      "clever\n",
      "11088\n",
      "11089\n",
      "11091\n",
      "11093\n",
      "11094\n",
      "11096\n",
      "clown\n",
      "11379\n",
      "11380\n",
      "11382\n",
      "11384\n",
      "65372\n",
      "coach\n",
      "11436\n",
      "11437\n",
      "11438\n",
      "11439\n",
      "11441\n",
      "11444\n",
      "coat\n",
      "11470\n",
      "11471\n",
      "11473\n",
      "11476\n",
      "69271\n",
      "cochlear implant\n",
      "11498\n",
      "11499\n",
      "11500\n",
      "11501\n",
      "11503\n",
      "11504\n",
      "65373\n",
      "coconut\n",
      "11527\n",
      "11528\n",
      "11529\n",
      "11534\n",
      "65374\n",
      "common\n",
      "12013\n",
      "12014\n",
      "12016\n",
      "12020\n",
      "69276\n",
      "commute\n",
      "12072\n",
      "12073\n",
      "12074\n",
      "12076\n",
      "12079\n",
      "control\n",
      "13042\n",
      "13043\n",
      "13044\n",
      "13046\n",
      "13049\n",
      "count\n",
      "13530\n",
      "13531\n",
      "13532\n",
      "13534\n",
      "13536\n",
      "65413\n",
      "culture\n",
      "14254\n",
      "14261\n",
      "14267\n",
      "65428\n",
      "daily\n",
      "14577\n",
      "14578\n",
      "14580\n",
      "14584\n",
      "65433\n",
      "defend\n",
      "15213\n",
      "15214\n",
      "15215\n",
      "15217\n",
      "15219\n",
      "degree\n",
      "15293\n",
      "15294\n",
      "15296\n",
      "15297\n",
      "15302\n",
      "65454\n",
      "demonstrate\n",
      "15474\n",
      "15475\n",
      "15476\n",
      "15477\n",
      "15479\n",
      "15481\n",
      "department\n",
      "15577\n",
      "15578\n",
      "15584\n",
      "65464\n",
      "die\n",
      "16161\n",
      "16164\n",
      "16168\n",
      "65479\n",
      "dig\n",
      "16231\n",
      "16233\n",
      "16235\n",
      "16238\n",
      "16241\n",
      "dinner\n",
      "16322\n",
      "16323\n",
      "16324\n",
      "16325\n",
      "16327\n",
      "16328\n",
      "16330\n",
      "dinosaur\n",
      "16333\n",
      "16334\n",
      "16335\n",
      "16336\n",
      "16337\n",
      "16342\n",
      "65483\n",
      "diploma\n",
      "16351\n",
      "16352\n",
      "16354\n",
      "16355\n",
      "16358\n",
      "director\n",
      "16383\n",
      "16384\n",
      "16386\n",
      "65484\n",
      "disconnect\n",
      "16525\n",
      "16526\n",
      "16527\n",
      "16528\n",
      "16530\n",
      "16531\n",
      "65488\n",
      "65489\n",
      "discover\n",
      "16560\n",
      "16561\n",
      "16562\n",
      "16563\n",
      "16564\n",
      "16567\n",
      "16569\n",
      "don_t want\n",
      "17298\n",
      "17300\n",
      "17301\n",
      "17302\n",
      "17306\n",
      "65518\n",
      "drum\n",
      "17896\n",
      "17897\n",
      "17900\n",
      "65547\n",
      "69303\n",
      "pervideo\n",
      "sun\n",
      "55803\n",
      "55804\n",
      "55805\n",
      "55806\n",
      "55808\n",
      "55814\n",
      "support\n",
      "55976\n",
      "55977\n",
      "55978\n",
      "55979\n",
      "55981\n",
      "55984\n",
      "suppose\n",
      "55996\n",
      "55999\n",
      "56003\n",
      "69497\n",
      "sure\n",
      "56029\n",
      "56030\n",
      "56031\n",
      "56035\n",
      "56038\n",
      "surprise\n",
      "56105\n",
      "56106\n",
      "56107\n",
      "56108\n",
      "56111\n",
      "66583\n",
      "sweater\n",
      "56247\n",
      "56248\n",
      "56249\n",
      "56251\n",
      "56254\n",
      "66584\n",
      "swim\n",
      "56341\n",
      "56343\n",
      "56344\n",
      "56348\n",
      "symbol\n",
      "56461\n",
      "56462\n",
      "56463\n",
      "56464\n",
      "56465\n",
      "56471\n",
      "taste\n",
      "56970\n",
      "56971\n",
      "56972\n",
      "56973\n",
      "56975\n",
      "56978\n",
      "team\n",
      "57090\n",
      "57091\n",
      "57092\n",
      "57093\n",
      "57096\n",
      "57099\n",
      "telephone\n",
      "57236\n",
      "57237\n",
      "57238\n",
      "57239\n",
      "57241\n",
      "57243\n",
      "tennis\n",
      "57410\n",
      "57411\n",
      "57412\n",
      "57413\n",
      "57415\n",
      "57417\n",
      "their\n",
      "57725\n",
      "57726\n",
      "57728\n",
      "57729\n",
      "57730\n",
      "then\n",
      "57771\n",
      "57772\n",
      "57774\n",
      "57777\n",
      "66602\n",
      "thermometer\n",
      "57840\n",
      "57842\n",
      "57843\n",
      "57849\n",
      "57850\n",
      "thing\n",
      "57922\n",
      "57923\n",
      "57925\n",
      "57928\n",
      "66608\n",
      "69504\n",
      "third\n",
      "58006\n",
      "58008\n",
      "58009\n",
      "58013\n",
      "58014\n",
      "58016\n",
      "66614\n",
      "thousand\n",
      "58132\n",
      "58133\n",
      "58136\n",
      "58137\n",
      "58139\n",
      "66629\n",
      "three\n",
      "58182\n",
      "58183\n",
      "58185\n",
      "58186\n",
      "58188\n",
      "66630\n",
      "69508\n",
      "tie\n",
      "58427\n",
      "58428\n",
      "58430\n",
      "58434\n",
      "58435\n",
      "58439\n",
      "66642\n",
      "topic\n",
      "58946\n",
      "58947\n",
      "58948\n",
      "58949\n",
      "58951\n",
      "58953\n",
      "66659\n",
      "touch\n",
      "59051\n",
      "59052\n",
      "59053\n",
      "59055\n",
      "59058\n",
      "tournament\n",
      "59103\n",
      "59104\n",
      "59105\n",
      "59106\n",
      "59107\n",
      "59108\n",
      "59110\n",
      "try\n",
      "59848\n",
      "59849\n",
      "59851\n",
      "59854\n",
      "66680\n",
      "66681\n",
      "two\n",
      "60220\n",
      "60221\n",
      "60224\n",
      "60225\n",
      "60227\n",
      "69521\n",
      "type\n",
      "60304\n",
      "60305\n",
      "60308\n",
      "60309\n",
      "60312\n",
      "umbrella\n",
      "60379\n",
      "60380\n",
      "60381\n",
      "60383\n",
      "60385\n",
      "66699\n",
      "vegetable\n",
      "61365\n",
      "61368\n",
      "61370\n",
      "61371\n",
      "66720\n",
      "vocabulary\n",
      "61879\n",
      "61881\n",
      "61882\n",
      "61886\n",
      "61889\n",
      "66735\n",
      "waste\n",
      "62423\n",
      "62424\n",
      "62427\n",
      "62430\n",
      "66750\n",
      "we\n",
      "62774\n",
      "62775\n",
      "62776\n",
      "62778\n",
      "62780\n",
      "66755\n",
      "69527\n",
      "wear\n",
      "62614\n",
      "62615\n",
      "62618\n",
      "62619\n",
      "62622\n",
      "66756\n",
      "weekly\n",
      "62754\n",
      "62756\n",
      "62757\n",
      "62761\n",
      "welcome\n",
      "62829\n",
      "62833\n",
      "62837\n",
      "66763\n",
      "66764\n",
      "winter\n",
      "63495\n",
      "63496\n",
      "63497\n",
      "63499\n",
      "63502\n",
      "63504\n",
      "without\n",
      "63607\n",
      "63608\n",
      "63609\n",
      "63610\n",
      "63612\n",
      "63615\n",
      "66796\n",
      "wolf\n",
      "63653\n",
      "63654\n",
      "63656\n",
      "63657\n",
      "63659\n",
      "66797\n",
      "worm\n",
      "63850\n",
      "63851\n",
      "63853\n",
      "63856\n",
      "66808\n",
      "69541\n",
      "wristwatch\n",
      "64042\n",
      "64043\n",
      "64044\n",
      "64046\n",
      "64048\n",
      "66814\n",
      "yourself\n",
      "64445\n",
      "64446\n",
      "64447\n",
      "64448\n",
      "64451\n"
     ]
    }
   ],
   "source": [
    "# feed to the dataset huhuyy\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.fft import fft, ifft\n",
    "\n",
    "\n",
    "def load_feature_from_folder(folder):\n",
    "  img = []\n",
    "  data = []\n",
    "  for folderName in os.listdir(folder):\n",
    "    print(folderName)\n",
    "    folder1 = os.path.join(folder, folderName)\n",
    "    for foll in os.listdir(folder1):\n",
    "      print(foll)\n",
    "      folder2 = os.path.join(folder1, foll)\n",
    "      cnt = 0\n",
    "      for fileInside in os.listdir(folder2):\n",
    "        pathLengkap = os.path.join(folder2, fileInside)\n",
    "        namaClass = folderName\n",
    "        # mp_image = mp.Image.create_from_file(pathLengkap)\n",
    "        # result, err = getFiturLandmark(mp_image)\n",
    "        \n",
    "        \n",
    "        if(True):\n",
    "          try:\n",
    "            # pose_landmarks_list = result.pose_landmarks\n",
    "            # dfpose = pd.DataFrame(pose_landmarks_list[0])\n",
    "            # print(cnt)\n",
    "            # print(pose_landmarks_list[0])\n",
    "            # hasil1 = flatten(dfpose)\n",
    "            # hasilfft = np.fft.fft(hasil1)\n",
    "            masuk_data = {\n",
    "              'class': namaClass,\n",
    "              'namaFile': foll,\n",
    "              'urutan': cnt,\n",
    "              # 'feature_lengkap': dfpose,\n",
    "              # 'triangle_feature': hasil1,\n",
    "              # 'fourier_feature': hasilfft\n",
    "            }\n",
    "            cnt = cnt + 1\n",
    "            data.append(masuk_data)\n",
    "            # print(data)\n",
    "          except:\n",
    "            print(pathLengkap)\n",
    "        else:\n",
    "          continue\n",
    "  dataFrame = pd.DataFrame(data)\n",
    "  dataFrame.to_pickle(\"data_keypoint_fitur_lengkap_pickle\")\n",
    "         \n",
    "path_dataset = \"../../dataset/extractFrame\"\n",
    "load_feature_from_folder(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat listfile csv\n",
    "\n",
    "def createListFile(_folder):\n",
    "    _data = []\n",
    "    for _folderName in os.listdir(_folder):\n",
    "        print(_folderName)\n",
    "        _folder1 = os.path.join(_folder, _folderName)\n",
    "        for _foll in os.listdir(_folder1):\n",
    "            print(_foll)\n",
    "            _folder2 = os.path.join(_folder1, _foll)\n",
    "            cnt = 0\n",
    "            for _fileInside in os.listdir(_folder2):\n",
    "                _pathLengkap = os.path.join(_folder2, _fileInside)\n",
    "                _namaClass = os.path.join(_folderName,_foll, _fileInside)\n",
    "                print(_namaClass)\n",
    "                _data.append(_namaClass)\n",
    "    \n",
    "    _dtframe = pd.DataFrame(_data)\n",
    "    _dtframe.to_pickle(\"list_file\")\n",
    "\n",
    "path_dataset = \"../../dataset/extractFrame\"\n",
    "# createListFile(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset class\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class dataClass(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.file = pd.read_pickle(\"list_file\")\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _path_depan = self.root_dir\n",
    "        _path_belakang = self.file.iloc[index,0]\n",
    "        _path_belakang = _path_belakang.replace(os.sep, '/')\n",
    "        _path_lengkap = os.path.join(_path_depan, _path_belakang)\n",
    "        _image = cv2.imread(_path_lengkap)\n",
    "        _mpImage = mp.Image.create_from_file(_path_lengkap)\n",
    "        _result, _err = getFiturLandmark(_mpImage)\n",
    "        _pose_landmarks_list = _result.pose_landmarks\n",
    "        if(len(_pose_landmarks_list)>0):\n",
    "            \n",
    "            _dfpose = pd.DataFrame(_pose_landmarks_list[0])\n",
    "            _dfposeFlatten = flatten(_dfpose)\n",
    "            _datareturn = {'path': _path_lengkap,\n",
    "                       'image': _image,\n",
    "                       'fitur_keypoint_lengkap': _result,\n",
    "                       'fitur_lengkap_flatten': _dfposeFlatten,\n",
    "                       }\n",
    "        else:\n",
    "            return self.__getitem__(index=index+1)\n",
    "        return _datareturn\n",
    "\n",
    "dataaset_torch = dataClass(csv_file=\"list_file\", root_dir=\"../../dataset/extractFrame/\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>namaFile</th>\n",
       "      <th>urutan</th>\n",
       "      <th>feature_lengkap</th>\n",
       "      <th>triangle_feature</th>\n",
       "      <th>fourier_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>above</td>\n",
       "      <td>00430</td>\n",
       "      <td>0</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.506881058216095, 0.2079756259918213, -0.689...</td>\n",
       "      <td>[(78.45452938933158+0j), (-4.464086183401866+3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>above</td>\n",
       "      <td>00430</td>\n",
       "      <td>1</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.5017372369766235, 0.2056875228881836, -0.77...</td>\n",
       "      <td>[(76.56170868576737+0j), (-3.980746325549271+3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>above</td>\n",
       "      <td>00430</td>\n",
       "      <td>2</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.5007808804512024, 0.20154517889022827, -0.5...</td>\n",
       "      <td>[(76.98094305739505+0j), (-3.169821885252973+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>above</td>\n",
       "      <td>00430</td>\n",
       "      <td>3</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.49879002571105957, 0.19752609729766846, -0....</td>\n",
       "      <td>[(75.20907570922282+0j), (-2.6053617781116314+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>above</td>\n",
       "      <td>00430</td>\n",
       "      <td>4</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.49864041805267334, 0.18816208839416504, -0....</td>\n",
       "      <td>[(75.98558826980297+0j), (-2.356283168908329+1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38725</th>\n",
       "      <td>yourself</td>\n",
       "      <td>64451</td>\n",
       "      <td>24</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.5141703486442566, 0.2702227234840393, -0.78...</td>\n",
       "      <td>[(76.11904963408597+0j), (-1.9968639410799702+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38726</th>\n",
       "      <td>yourself</td>\n",
       "      <td>64451</td>\n",
       "      <td>25</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.5149209499359131, 0.2688581943511963, -0.79...</td>\n",
       "      <td>[(75.3994476548396+0j), (-1.6359811104954964+2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38727</th>\n",
       "      <td>yourself</td>\n",
       "      <td>64451</td>\n",
       "      <td>26</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.5143306851387024, 0.2708406448364258, -0.78...</td>\n",
       "      <td>[(75.75465970579535+0j), (-1.9866186968249133+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38728</th>\n",
       "      <td>yourself</td>\n",
       "      <td>64451</td>\n",
       "      <td>27</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.5157540440559387, 0.2723342180252075, -0.80...</td>\n",
       "      <td>[(75.77654468570836+0j), (-1.8139997132680858+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38729</th>\n",
       "      <td>yourself</td>\n",
       "      <td>64451</td>\n",
       "      <td>28</td>\n",
       "      <td>x         y         z  visibility  ...</td>\n",
       "      <td>[0.5163243412971497, 0.2681657075881958, -0.71...</td>\n",
       "      <td>[(77.02725050738081+0j), (-2.2649032091483607+...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38730 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          class namaFile  urutan  \\\n",
       "0         above    00430       0   \n",
       "1         above    00430       1   \n",
       "2         above    00430       2   \n",
       "3         above    00430       3   \n",
       "4         above    00430       4   \n",
       "...         ...      ...     ...   \n",
       "38725  yourself    64451      24   \n",
       "38726  yourself    64451      25   \n",
       "38727  yourself    64451      26   \n",
       "38728  yourself    64451      27   \n",
       "38729  yourself    64451      28   \n",
       "\n",
       "                                         feature_lengkap  \\\n",
       "0                 x         y         z  visibility  ...   \n",
       "1                 x         y         z  visibility  ...   \n",
       "2                 x         y         z  visibility  ...   \n",
       "3                 x         y         z  visibility  ...   \n",
       "4                 x         y         z  visibility  ...   \n",
       "...                                                  ...   \n",
       "38725             x         y         z  visibility  ...   \n",
       "38726             x         y         z  visibility  ...   \n",
       "38727             x         y         z  visibility  ...   \n",
       "38728             x         y         z  visibility  ...   \n",
       "38729             x         y         z  visibility  ...   \n",
       "\n",
       "                                        triangle_feature  \\\n",
       "0      [0.506881058216095, 0.2079756259918213, -0.689...   \n",
       "1      [0.5017372369766235, 0.2056875228881836, -0.77...   \n",
       "2      [0.5007808804512024, 0.20154517889022827, -0.5...   \n",
       "3      [0.49879002571105957, 0.19752609729766846, -0....   \n",
       "4      [0.49864041805267334, 0.18816208839416504, -0....   \n",
       "...                                                  ...   \n",
       "38725  [0.5141703486442566, 0.2702227234840393, -0.78...   \n",
       "38726  [0.5149209499359131, 0.2688581943511963, -0.79...   \n",
       "38727  [0.5143306851387024, 0.2708406448364258, -0.78...   \n",
       "38728  [0.5157540440559387, 0.2723342180252075, -0.80...   \n",
       "38729  [0.5163243412971497, 0.2681657075881958, -0.71...   \n",
       "\n",
       "                                         fourier_feature  \n",
       "0      [(78.45452938933158+0j), (-4.464086183401866+3...  \n",
       "1      [(76.56170868576737+0j), (-3.980746325549271+3...  \n",
       "2      [(76.98094305739505+0j), (-3.169821885252973+0...  \n",
       "3      [(75.20907570922282+0j), (-2.6053617781116314+...  \n",
       "4      [(75.98558826980297+0j), (-2.356283168908329+1...  \n",
       "...                                                  ...  \n",
       "38725  [(76.11904963408597+0j), (-1.9968639410799702+...  \n",
       "38726  [(75.3994476548396+0j), (-1.6359811104954964+2...  \n",
       "38727  [(75.75465970579535+0j), (-1.9866186968249133+...  \n",
       "38728  [(75.77654468570836+0j), (-1.8139997132680858+...  \n",
       "38729  [(77.02725050738081+0j), (-2.2649032091483607+...  \n",
       "\n",
       "[38730 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lengkap = pd.read_pickle(\"../../dataset/data_keypoint_fitur_lengkap_pickle\")\n",
    "# data_lengkap.iloc[0][\"triangle_feature\"]\n",
    "a = data_lengkap\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LSTM model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
