{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scipy.fft import fft, ifft\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = v2.Compose(\n",
    "    [\n",
    "    v2.ToImage(),\n",
    "    v2.Resize([100,160]),\n",
    "    # v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dir, transform ):\n",
    "        super().__init__()\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "        self.list_of_frames, self.list_of_class_id, self.list_of_class_name = self.walk(self.dir)\n",
    "        \n",
    "        self.list_map_class = self.makeDictClass(dir=self.dir)\n",
    "    \n",
    "    def video2frame(self,videopath):\n",
    "        _video = cv2.VideoCapture(videopath)\n",
    "        _fps_in = _video.get(cv2.CAP_PROP_FPS)\n",
    "        _count = 0\n",
    "        _success = 1\n",
    "        _frames = []\n",
    "        \n",
    "        _fps_out = 30\n",
    "\n",
    "        _index_in = -1\n",
    "        _index_out = -1\n",
    "        \n",
    "        # get class name\n",
    "        _path = os.path.split(videopath)\n",
    "        _path2class = os.path.split(_path[0])\n",
    "        _className = _path2class[1]\n",
    "        print(_className)\n",
    "        \n",
    "        # convert classname to id\n",
    "        _map_class = self.makeDictClass(dir=self.dir)\n",
    "        _classId = self.class2id(classname=_className, dictclass=_map_class)\n",
    "        \n",
    "        \n",
    "        # extract video to frame\n",
    "        while _success:\n",
    "            _success = _video.grab()\n",
    "            if not _success: break\n",
    "            _index_in += 1\n",
    "            _out_due = int(_index_in / _fps_in * _fps_out)\n",
    "            if _out_due > _index_out:\n",
    "                _success, _frame = _video.read()\n",
    "                if(_success==True):\n",
    "                    # print(_success)\n",
    "                    _transformed = transform(_frame)\n",
    "                    # print(_transformed.shape)\n",
    "                    _frames.append(_transformed)\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        _video.release()\n",
    "        \n",
    "            \n",
    "        return _frames, _classId, _className\n",
    "    \n",
    "    def makeDictClass(self, dir):\n",
    "        dictClass = {}\n",
    "        i = 0\n",
    "        for _i in os.listdir(dir):\n",
    "            if (os.path.isdir(os.path.join(dir, _i)) == True):\n",
    "                # print(_i)\n",
    "                dictClass[i] = _i\n",
    "                i = i + 1\n",
    "        return dictClass\n",
    "\n",
    "    def class2id(self, classname, dictclass):\n",
    "        id = 0\n",
    "        for i in dictclass:\n",
    "            if (dictclass[i] == classname):\n",
    "                id = i\n",
    "                break\n",
    "        return id\n",
    "        \n",
    "    def walk(self, dir):\n",
    "        list_of_frames = []\n",
    "        list_of_class_name = []\n",
    "        list_of_class_id = []\n",
    "        \n",
    "        for _i in os.listdir(dir):\n",
    "           \n",
    "            for _j in os.listdir(os.path.join(dir, _i)):\n",
    "                _pathFile = os.path.join(dir, _i, _j)\n",
    "                _pathFile = _pathFile.replace(os.sep, \"/\")\n",
    "                _frames, _classId, _classname = self.video2frame(_pathFile)\n",
    "                _frames = torch.stack(_frames)\n",
    "                list_of_frames.append(_frames)\n",
    "                # print(_frames.shape)\n",
    "                # print(len(_frames))\n",
    "                # list_of_frames = torch.stack(_frames)\n",
    "                list_of_class_name.append(_classname)\n",
    "                list_of_class_id.append(_classId)\n",
    "        \n",
    "        # list_of_frames = torch.stack(list_of_frames)\n",
    "        list_of_frames_pad = pad_sequence(list_of_frames, batch_first=True)\n",
    "        return list_of_frames_pad, list_of_class_id, list_of_class_name\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.list_of_frames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        class_name = self.list_of_class_name[idx]\n",
    "        class_id = self.list_of_class_id[idx]\n",
    "        frames = self.list_of_frames[idx]\n",
    "        # print(frames)\n",
    "        \n",
    "        return frames, class_id, class_name\n",
    "                \n",
    "        \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abdomen\n",
      "abdomen\n",
      "abdomen\n",
      "abdomen\n",
      "abdomen\n",
      "accent\n",
      "accent\n",
      "accent\n",
      "accent\n",
      "accent\n",
      "accept\n",
      "accept\n",
      "accept\n",
      "accept\n",
      "accept\n",
      "accept\n",
      "accept\n",
      "accept\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "accident\n",
      "affect\n",
      "affect\n",
      "affect\n",
      "affect\n",
      "affect\n",
      "affect\n",
      "again\n",
      "again\n",
      "again\n",
      "again\n",
      "again\n",
      "again\n",
      "again\n",
      "again\n",
      "ago\n",
      "ago\n",
      "ago\n",
      "ago\n",
      "ago\n",
      "ago\n",
      "ago\n",
      "ago\n",
      "ago\n",
      "aim\n",
      "aim\n",
      "aim\n",
      "aim\n",
      "aim\n",
      "already\n",
      "already\n",
      "already\n",
      "already\n",
      "already\n",
      "already\n",
      "already\n",
      "already\n",
      "annoy\n",
      "annoy\n",
      "annoy\n",
      "annoy\n",
      "appear\n",
      "appear\n",
      "appear\n",
      "appear\n",
      "appear\n",
      "appear\n",
      "appear\n",
      "appointment\n",
      "appointment\n",
      "appointment\n",
      "appointment\n",
      "appointment\n",
      "appointment\n",
      "appointment\n",
      "appointment\n",
      "appointment\n",
      "appointment\n",
      "approve\n",
      "approve\n",
      "approve\n",
      "approve\n",
      "approve\n",
      "approve\n",
      "approve\n",
      "approve\n",
      "arm\n",
      "arm\n",
      "arm\n",
      "arm\n",
      "arm\n",
      "arm\n",
      "arm\n",
      "arrest\n",
      "arrest\n",
      "arrest\n",
      "arrest\n",
      "arrest\n",
      "arrest\n",
      "article\n",
      "article\n",
      "article\n",
      "article\n",
      "authority\n",
      "authority\n",
      "authority\n",
      "authority\n",
      "authority\n",
      "aware\n",
      "aware\n",
      "aware\n",
      "aware\n",
      "babysitter\n",
      "babysitter\n",
      "babysitter\n",
      "babysitter\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n",
      "bad\n"
     ]
    }
   ],
   "source": [
    "dir='../../dataset/WLASL100/'\n",
    "data_torch = VideoDataset(dir=dir, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data.dataloader\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(dataset=data_torch, lengths=([0.8,0.2]))\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=1, drop_last=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=1, drop_last=True)\n",
    "print(len(train_data_loader))\n",
    "print(len(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n",
      "torch.Size([1, 92, 3, 100, 160])\n"
     ]
    }
   ],
   "source": [
    "for i in test_data_loader:\n",
    "    print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class VideoRecognitionModel(nn.Module):\n",
    "    def __init__(self, num_classes, num_frames, embed_dim, num_heads, num_layers, hidden_dim):\n",
    "        super(VideoRecognitionModel, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Load a pre-trained MobileNet model from timm\n",
    "        self.mobilenet = timm.create_model('mobilenetv3_large_100', pretrained=True, features_only=True)\n",
    "        \n",
    "        # Remove the last layer to get feature maps\n",
    "        self.mobilenet.global_pool = nn.Identity()\n",
    "        self.mobilenet.classifier = nn.Identity()\n",
    "        \n",
    "        # Feature dimension from MobileNet\n",
    "        self.feature_dim = 960  # For mobilenetv3_large_100, adjust if using a different model\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.embed_dim = embed_dim\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, num_frames, embed_dim))\n",
    "        encoder_layers = TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_frames, channels, height, width)\n",
    "        batch_size, num_frames, channels, height, width = x.shape\n",
    "        \n",
    "        # Process each frame through MobileNet\n",
    "        features = []\n",
    "        for t in range(num_frames):\n",
    "            frame = x[:, t, :, :, :]  # Extract frame at time t\n",
    "            frame_features = self.mobilenet(frame)  # Extract features using MobileNet\n",
    "            frame_features = frame_features[-1]  # Use the last feature map\n",
    "            frame_features = frame_features.mean([2, 3])  # Global average pooling\n",
    "            features.append(frame_features)\n",
    "        \n",
    "        # Stack features along the time dimension\n",
    "        features = torch.stack(features, dim=1)  # Shape: (batch_size, num_frames, feature_dim)\n",
    "        \n",
    "        # Project features to the embedding dimension\n",
    "        features = nn.Linear(self.feature_dim, self.embed_dim).to(device)(features)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        features = features + self.positional_encoding\n",
    "        \n",
    "        # Pass through Transformer Encoder\n",
    "        transformer_output = self.transformer_encoder(features)  # Shape: (batch_size, num_frames, embed_dim)\n",
    "        \n",
    "        # Aggregate over time (e.g., mean pooling)\n",
    "        aggregated_output = transformer_output.mean(dim=1)\n",
    "        \n",
    "        # Final classification\n",
    "        output = self.fc(aggregated_output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 20  # Number of classes for classification\n",
    "num_frames = 92   # Number of frames in the video\n",
    "embed_dim = 512   # Embedding dimension for Transformer\n",
    "num_heads = 8     # Number of attention heads\n",
    "num_layers = 2    # Number of Transformer layers\n",
    "hidden_dim = 1024 # Hidden dimension in Transformer feed-forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "d:\\miniconda\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = VideoRecognitionModel(num_classes, num_frames, embed_dim, num_heads, num_layers, hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VideoRecognitionModel(\n",
       "  (mobilenet): MobileNetV3Features(\n",
       "    (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): Hardswish()\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): Identity()\n",
       "          (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (aa): Identity()\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (global_pool): Identity()\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3968,  0.0950, -0.0312, -1.3888, -0.0100, -0.0032,  0.7392,  0.6924,\n",
      "          0.6920,  0.2462,  0.3348, -0.0523, -0.5238, -1.1940, -0.4603,  0.1687,\n",
      "          0.3902, -0.3159, -0.1865,  0.8156]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, num_frames, 3, 224, 224)\n",
    "aa = model(dummy_input.to(device))\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class tensor([15], device='cuda:0')\n",
      "pred tensor([[ 0.5859, -0.4739, -1.4033, -3.0098,  1.1526, -1.1138, -0.2305, -0.2424,\n",
      "         -0.8428,  1.0511, -0.4722, -0.5178,  1.5815, -0.4632, -0.2127,  0.2286,\n",
      "         -0.2402,  0.2237, -0.2527, -0.5069]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(2.9186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([8], device='cuda:0')\n",
      "pred tensor([[ 2.2782, -1.3372, -1.4782,  1.4679,  0.5165,  0.4883, -1.1585,  0.7047,\n",
      "          1.1832,  0.4331, -0.5837, -1.3998,  1.0021, -0.9567, -0.6248, -1.3765,\n",
      "          0.0225,  0.7187, -0.7950,  0.5833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(2.3738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([12], device='cuda:0')\n",
      "pred tensor([[ 1.1732, -0.7650,  0.0911,  1.4074,  1.0134, -0.7325, -0.7429,  0.2196,\n",
      "          0.3273, -0.1509,  2.2693, -1.6234,  0.1930, -1.7144,  0.5763, -1.8095,\n",
      "          0.4832, -1.6478, -0.8735,  0.8641]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(3.3302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([7], device='cuda:0')\n",
      "pred tensor([[ 0.0703, -1.3416, -0.9134, -1.4300,  1.1833,  3.5697,  0.0644, -1.4148,\n",
      "          1.3661, -0.1646, -0.3391, -0.6613,  0.4258, -0.6299,  2.4963, -0.8164,\n",
      "         -0.2472, -1.8144, -1.4053,  1.3470]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(5.6304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([3], device='cuda:0')\n",
      "pred tensor([[-0.1926, -1.4319, -1.2742,  0.3290,  0.0673,  2.2125, -0.8878, -0.2415,\n",
      "          1.4994, -1.2094, -0.8442, -1.6997,  1.2317, -0.1662,  1.6299, -1.0789,\n",
      "         -1.2612, -0.3407, -1.6662,  1.8620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(3.2783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([16], device='cuda:0')\n",
      "pred tensor([[ 1.0667, -0.2865, -0.8471,  0.5666, -0.0079,  0.5492, -1.9259,  1.9721,\n",
      "          2.5593,  0.7235, -0.3693, -0.1720,  0.1204, -0.9087,  0.7989, -1.0096,\n",
      "         -1.5746,  1.3955, -0.1961,  1.0584]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(5.3699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([13], device='cuda:0')\n",
      "pred tensor([[ 1.7195, -1.2089, -0.2928,  2.8565,  1.6993,  0.6662, -2.5796, -0.7374,\n",
      "          2.6717, -0.0142, -0.4708, -2.2884,  1.0653, -0.2120, -0.5789,  0.3883,\n",
      "         -0.5237, -1.8828, -0.7261, -0.7941]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(4.2302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([5], device='cuda:0')\n",
      "pred tensor([[-0.8964, -0.7753,  0.9315,  2.9512,  0.3324,  0.5512, -0.7564, -1.3466,\n",
      "          1.3769, -0.7308, -1.4779, -1.9332,  1.7791,  1.1552,  0.8382, -1.1694,\n",
      "          0.3179, -0.2356, -0.9238,  0.3752]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(3.2979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([3], device='cuda:0')\n",
      "pred tensor([[ 1.0764,  0.0908, -0.2850, -0.7030, -0.9809,  0.1369, -0.3517, -2.2586,\n",
      "          2.3168, -0.6911, -3.1422, -0.3183,  0.2426,  1.5396,  1.0254,  0.0693,\n",
      "          0.8508,  0.0273, -0.6601,  1.1425]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(4.2820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([2], device='cuda:0')\n",
      "pred tensor([[-0.0178, -1.3456,  0.4699,  0.6244, -0.4458,  0.4453, -0.0026, -0.4835,\n",
      "          0.7301, -0.0340, -1.2417, -1.2302,  1.8943, -0.6366,  0.6489, -1.0664,\n",
      "          0.0442,  0.9477, -0.9564,  0.1620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(2.8173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([16], device='cuda:0')\n",
      "pred tensor([[ 0.4240, -0.6281, -0.1288,  1.7358,  1.0814, -2.3011, -1.9138,  0.0672,\n",
      "         -1.6638, -1.0521, -0.1382, -1.9315,  2.3632,  2.1513,  1.7645, -0.0678,\n",
      "         -0.7102, -1.8313, -0.6439, -1.6273]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(4.4432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([11], device='cuda:0')\n",
      "pred tensor([[ 1.2671, -1.0294,  1.1427,  1.1738, -0.5507,  0.6294, -0.6794, -0.6368,\n",
      "         -0.6539,  0.4145, -0.4914, -1.7154,  1.4391, -0.8827,  0.8493, -1.0303,\n",
      "         -0.2419, -0.2173,  0.3292,  1.4116]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(5.1493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([12], device='cuda:0')\n",
      "pred tensor([[ 1.1371,  0.0734,  0.0481,  1.4485,  0.0670,  1.9495,  0.7564,  1.3767,\n",
      "          2.7886, -0.1121, -1.1960, -3.1333, -1.9743,  0.2870,  0.2122, -1.6656,\n",
      "         -0.1178, -1.3643, -0.7833,  0.0930]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(5.8198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([3], device='cuda:0')\n",
      "pred tensor([[ 0.7706, -1.0207,  0.3245, -1.4535,  2.3893,  0.5648, -2.2606, -0.6952,\n",
      "         -2.3825, -0.3336, -0.2158, -0.3629,  1.2595,  2.7950,  0.4624,  1.5492,\n",
      "          0.8135, -0.5896, -1.0606, -0.8289]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(5.3553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([19], device='cuda:0')\n",
      "pred tensor([[-0.4935, -0.8849, -0.0302,  0.3090, -0.2787,  1.6731, -1.3760, -0.4118,\n",
      "          1.2219, -0.5930, -2.4000,  0.2291,  1.2527,  2.4824,  0.8864, -1.0776,\n",
      "          0.1390, -0.5531, -1.0207,  0.7483]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(2.8915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([10], device='cuda:0')\n",
      "pred tensor([[ 1.0437, -1.4679, -1.8329,  0.9097,  0.8223, -0.0171, -0.3130, -0.7764,\n",
      "          2.7233, -0.9389, -2.6257,  2.1586,  0.0191,  0.1570,  0.7714,  0.0961,\n",
      "         -0.0835, -0.1680, -1.7742,  0.5750]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(6.4026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([5], device='cuda:0')\n",
      "pred tensor([[-0.7673, -1.0781,  0.4510, -0.8763,  0.8312,  0.5454, -0.6250,  0.9572,\n",
      "         -3.4831, -1.8994, -0.7975,  0.7184,  0.6811,  1.8291,  0.4179,  1.8351,\n",
      "          1.6913, -0.0495, -0.3593,  0.0640]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(3.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([3], device='cuda:0')\n",
      "pred tensor([[-0.5072, -0.4897, -1.1805, -0.5702, -0.6355,  0.4615, -0.3333,  1.6387,\n",
      "         -0.6220, -0.9332, -0.1789, -1.7347,  3.1625, -0.3454,  0.4948,  1.1321,\n",
      "          1.6445,  0.2002, -0.5975, -0.6442]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(4.4531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([6], device='cuda:0')\n",
      "pred tensor([[ 0.2422, -1.9564,  1.1483,  1.3419, -0.7931,  0.9642,  0.5792, -0.6507,\n",
      "          0.1029, -0.2557, -1.5011,  0.0393,  1.0293,  1.1464,  0.0217, -0.8679,\n",
      "          1.5075, -1.8407, -1.6157, -0.0342]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(2.8269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([11], device='cuda:0')\n",
      "pred tensor([[ 0.1450, -1.2359, -0.4424,  4.5578,  1.0685,  0.8091, -0.3937, -0.4784,\n",
      "          0.6337, -0.3827, -1.2408, -1.1037,  0.3883,  1.3226,  0.4179, -0.6242,\n",
      "          0.5959,  0.0404, -0.7760, -0.5695]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(5.8766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([8], device='cuda:0')\n",
      "pred tensor([[-1.7445, -1.4025,  0.4950,  1.9704,  1.1142, -0.0482,  1.5292,  0.6945,\n",
      "         -1.8178, -1.6610,  0.9852,  0.2029,  3.8794, -1.5414,  0.8086, -0.5063,\n",
      "          0.8211, -1.6948, -1.0169, -0.2827]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(6.1890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([13], device='cuda:0')\n",
      "pred tensor([[ 0.8740, -1.1191, -0.9748,  1.2105, -1.1019,  1.2902,  0.4536,  0.1724,\n",
      "          1.1418,  1.5279, -1.2189,  2.2443,  1.7573, -2.8908,  1.0243, -0.6897,\n",
      "         -0.2022, -0.1722, -0.8767, -0.0244]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(6.6483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "class tensor([10], device='cuda:0')\n",
      "pred tensor([[-0.5672,  0.1952, -0.6605,  3.4850, -1.5710, -1.1047, -0.9882, -0.2529,\n",
      "          0.4430, -0.4537,  0.4276,  0.7825, -1.4340, -0.1399,  0.2106, -1.7520,\n",
      "          0.4340, -1.0475, -1.4755,  0.3943]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(3.4570, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, target)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# print(output, b[1])\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    583\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "\n",
    "num_steps = len(train_data_loader)\n",
    "iterator = iter(train_data_loader)\n",
    "count_steps = 1   \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum=momentum, weight_decay=weight_decay) \n",
    "\n",
    "# print(train_data_loader.batch_size)\n",
    "\n",
    "for i in range(0,200):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    for a,b in enumerate(train_data_loader):\n",
    "        frames = b[0].to(device)\n",
    "        target = b[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # print(b[0].shape)\n",
    "        output = model(frames.float())\n",
    "       \n",
    "        loss = loss_fn(output, target)\n",
    "        # print(output, b[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print(\"class\", target)\n",
    "        print(\"pred\", output)\n",
    "        print(loss)\n",
    "    last_loss = running_loss / 1000\n",
    "    print(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
